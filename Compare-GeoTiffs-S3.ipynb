{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Cloud-Optimized Geotiffs from ASDI \"sentinel-s1-rtc-indigo\" S3 buckets \n",
    "\n",
    "This notebook shows an option on how to construct a multidimensional xarray DataArray from multiple 2D Images COGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-1 Radiometric Terrain Corrected (RTC) Data\n",
    "\n",
    "https://sentinel-s1-rtc-indigo-docs.s3-us-west-2.amazonaws.com/index.html\n",
    "\n",
    "The Sentinel-1 mission is a constellation of two C-band Synthetic Aperature Radar (SAR) imaging satellites from the European Space Agency (ESA). These satellites were launched in 2014 (S1A) and 2016 (S1B) and are capable of providing imagery in all-weather, day or night, under a few different observation configurations. Each satellite has a repeat cycle of 12-days and completes 175 orbits per cycle, giving it a potential 6-day repeat coverage time.\n",
    "\n",
    " he Sentinel-1 data included in this dataset are from the “Interferometric Wide Swath” (IW) mode, which is the main acquisition mode over land. The data were first preprocesed by ESA into a Level-1 “Ground Range Detected” (GRD) product, which involves detection, multi-looking, and projection to ground-range using a simple Earth ellipsoid model.\n",
    "\n",
    "We have applied additional processing steps on top of the “GRD” product to make it “Radiometric Terrain Corrected” (RTC), including calibration, noise removal, speckle filtering, and radiometric and terrain correction. We also transform the dataset from a collection of “scenes”, or slices of orbital passes, into a regularly gridded, “tiled” data product. We perform these steps to make the imagery suitable for analysis, but some preprocessing choices may not fit your application. For more information, see the Methodology section.\n",
    "\n",
    "This product is available for the Contiguous United States (CONUS) only, which has been mapped routinely over the enter domain since 2017 in dual-vertical (DV) polarization mode on ascending orbits. We update the dataset with newly acquired Sentinel-1 data on a daily cadence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please use the environement.ymal file to cretea the needed environement with conda\n",
    "#pip install rioxarray intake intake-xarray rasterio datashader s3fs hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import s3fs\n",
    "import intake\n",
    "import os\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same GDAL environment settings as we did for the single COG case\n",
    "env = dict(GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR', \n",
    "           AWS_NO_SIGN_REQUEST='YES',\n",
    "           GDAL_MAX_RAW_BLOCK_CACHE_SIZE='2000000000',\n",
    "           GDAL_SWATH_SIZE='2000000000',\n",
    "           VSI_CURL_CACHE_SIZE='2000000000')\n",
    "os.environ.update(env)\n",
    "\n",
    "#define year in scope\n",
    "year = '2019'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sentinel-s1-rtc-indigo-docs.s3-us-west-2.amazonaws.com/data_format.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up a connection with credentials and other settings\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "objects = s3.ls('sentinel-s1-rtc-indigo/tiles/RTC/1/IW/19/T/DK/' + year + '/')\n",
    "images = ['s3://' + obj + '/Gamma0_VV.tif' for obj in objects]\n",
    "print(len(images))\n",
    "images[:] \n",
    "\n",
    "#aws s3 ls --no-sign-request s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/10/T/ET/\n",
    "#s3://sentinel-s1-rtc-indigo/tiles/RTC/1/[MODE]=IW/[MGRS UTM zone]/[MGRS latitude label]/[MGRS Grid Square ID]/[YEAR]/[SATELLITE]_[DATE]_[TILE ID]_[ORBIT DIRECTION]/[ASSET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GDAL VRT file is an XML format that can group together many separate files into separate bands. \n",
    "It's common to create such a file with a the GDAL command line tool `gdalbuildvrt`, illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1) write a file list that points to the data. GDAL requires special prefixes for this /vsis3/ or /vsicurl/\n",
    "with open('files_runtime_inventory.txt', 'w') as f:\n",
    "    lines = [x.replace('s3://', '/vsis3/') + '\\n' for x in images[:]]\n",
    "    f.writelines(lines)\n",
    "    #print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# step 2) create a VRT file\n",
    "!gdalbuildvrt stack.vrt -separate -input_file_list files_runtime_inventory.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# step 4) open with xarray\n",
    "chunks=dict(band=1, x=2745, y=2745)\n",
    "#da = xr.open_rasterio('stack.vrt', chunks=chunks)\n",
    "ds = xr.open_dataset('stack.vrt', chunks=chunks, engine=\"rasterio\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5) optionally modify coordinates (e.g. time dimension extracted from file name)\n",
    "#ds = ds.rename({'band':'time'})\n",
    "#ds['time'] = [pd.to_datetime(x[60:68]) for x in images[:6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recap\n",
    "\n",
    "1. `xr.open_rasterio(stack.vrt)` stores band coordinates as sequential integers (we lose file name and metadata from each individual COG, so it's common to alter the coordinates after opening the dataset)\n",
    "2. data is tied to a reference to a local file ('stack.vrt'), which can cause problems with distributed computing if you don't have access to the local filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## intake-xarray\n",
    "\n",
    "[intake-xarray](https://github.com/intake/intake-xarray) is a plugin for the intake library. It uses fsspec/s3fs under the hood to facilitate loading data into python objects. the function `intake.open_rasterio()` accepts a list of paths. it returns an intake object with a `to_dask()` function that returns an xarray DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ~ 1s for 6 files\n",
    "\n",
    "# this loads the image ID into xarray's band coordinates. \n",
    "\n",
    "pattern = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/19/T/DK/' + year + '/{band}/Gamma0_VV.tif'\n",
    "chunks=dict(band=1, x=5490, y=5490)\n",
    "sources = intake.open_rasterio(images[:], chunks=chunks, path_as_pattern=pattern, concat_dim='band')\n",
    "da = sources.to_dask() \n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "da.hvplot.image(rasterize=True, aspect='equal', cmap='gray', clim=(0,0.4), frame_width=600, frame_height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom\n",
    "\n",
    "You can also just use xarray and dask to construct a larger datacube from many COGS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 4 - 8 s\n",
    "# Load all the images\n",
    "\n",
    "chunks=dict(band=1, x=2745, y=2745)\n",
    "dataArrays = [xr.open_dataset(url, chunks=chunks, engine=\"rasterio\") for url in images]\n",
    "\n",
    "# note use of join='override' b/c we know these COGS have the same coordinates\n",
    "da = xr.concat(dataArrays, dim='band', join='override', combine_attrs='drop')\n",
    "da = da.rename({'band':'time'})\n",
    "da['time'] = [pd.to_datetime(x[60:68]) for x in images]\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recap:\n",
    "\n",
    "* The cell above is essentially a for-loop that iterates over each COG in sequence. 50ms-200ms * 80 ~ 4-16 seconds. The next notebook will look at using Dask to speed things up by opening the files in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "Here is an example of interactive visualization again using hvplot. Since we're using full resolution arrays it's key to set the `rasterize=True` keyword argument. That uses the datashader library to pre-render images before sending them to the browser.\n",
    "\n",
    "This is extremely powerful because, resolution updates as you zoom in, and you can scrub through the data cube with an interactive slider widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "da.hvplot.image(rasterize=True, aspect='equal', cmap='gray', clim=(0,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
